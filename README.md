### A very simple bayesian model exercise to "correct" crude prevalence based on sensitivity and specificity

This is inspired by the [COVID-19 seroprevalence study](https://www.medrxiv.org/content/10.1101/2020.04.14.20062463v1.full.pdf) conducted in Santa Clara County of California. The study tested 3330 persons (not completely random) and found 50 persons had the SARS-CoV-2 antibodies, i.e. about 1.5% prevalence. They did some reweighting and conclude that, on average, the population prevalence was 2.5 to 4.2%. Which is high and the study immediately invited multiple (just) criticisms. Many criticisms were on the calculation of confidence intervals and specificity of the test kit. One long critic can be seen [here](https://statmodeling.stat.columbia.edu/2020/04/19/fatal-flaws-in-stanford-study-of-coronavirus-prevalence/).

I was thinking of how to "correct" the prevalence based on sensitivity and specificity information. And decided to do a simple exercise on it. This work is SIMPLE, and by no means usable for this particular study (or any others). But it's fun to model, it's fun to do Bayesian, so why not try something...
